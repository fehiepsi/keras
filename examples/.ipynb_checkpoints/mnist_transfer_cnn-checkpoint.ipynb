{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# init the random seed and keras things\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init the time function\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 128\n",
    "nb_classes = 5\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we use the model two times, so it is better to define a train\n",
    "# function (modular programming! using abstraction)\n",
    "def train_model(model, train, test, nb_classes):\n",
    "    X_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(train[1], nb_classes)\n",
    "    Y_test = np_utils.to_categorical(test[1], nb_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two datasets one with digits below 5 and one with 5 and above\n",
    "X_train_lt5 = X_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "X_test_lt5 = X_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "X_train_gte5 = X_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5  # make classes start at 0 for\n",
    "X_test_gte5 = X_test[y_test >= 5]         # np_utils.to_categorical\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define two groups of layers: feature (convolutions) and classification (dense)\n",
    "feature_layers = [\n",
    "    Convolution2D(nb_filters, kernel_size, kernel_size,\n",
    "                  border_mode='valid',\n",
    "                  input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Convolution2D(nb_filters, kernel_size, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "    Dropout(0.25),\n",
    "    Flatten()\n",
    "]\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(nb_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create complete model, use list here instead of series of .add()\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 5s - loss: 0.2149 - acc: 0.9348 - val_loss: 0.0398 - val_acc: 0.9872\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 3s - loss: 0.0627 - acc: 0.9812 - val_loss: 0.0233 - val_acc: 0.9922\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 3s - loss: 0.0447 - acc: 0.9870 - val_loss: 0.0192 - val_acc: 0.9926\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 3s - loss: 0.0361 - acc: 0.9885 - val_loss: 0.0148 - val_acc: 0.9946\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 3s - loss: 0.0300 - acc: 0.9912 - val_loss: 0.0152 - val_acc: 0.9947\n",
      "Training time: 0:00:18.610983\n",
      "Test score: 0.0151647937127\n",
      "Test accuracy: 0.994746059545\n"
     ]
    }
   ],
   "source": [
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model,\n",
    "            (X_train_lt5, y_train_lt5),\n",
    "            (X_test_lt5, y_test_lt5), nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# freeze feature layers and rebuild model\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 2s - loss: 0.3631 - acc: 0.8932 - val_loss: 0.0922 - val_acc: 0.9685\n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 1s - loss: 0.1226 - acc: 0.9627 - val_loss: 0.0599 - val_acc: 0.9803\n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 1s - loss: 0.0916 - acc: 0.9737 - val_loss: 0.0476 - val_acc: 0.9846\n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 1s - loss: 0.0744 - acc: 0.9775 - val_loss: 0.0397 - val_acc: 0.9864\n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 1s - loss: 0.0649 - acc: 0.9805 - val_loss: 0.0359 - val_acc: 0.9879\n",
      "Training time: 0:00:10.612115\n",
      "Test score: 0.0358572804061\n",
      "Test accuracy: 0.987862579606\n"
     ]
    }
   ],
   "source": [
    "# transfer: train dense layers for new classification task [5..9]\n",
    "train_model(model,\n",
    "            (X_train_gte5, y_train_gte5),\n",
    "            (X_test_gte5, y_test_gte5), nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Though we dont make the network learn how to identify numbers 5->9, the features extracted from the output of convolution layers (0->4) are enough to classify the numbers 5->9! Amazing!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
